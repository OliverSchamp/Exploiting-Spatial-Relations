# Exploiting-Spatial-Relations

## Overview

Using Transformers for Object Detection in Foosball. This is a GitHub repostiory for my thesis "Exploiting Spatial Relations for Object Detection with Transformers". Two models, DETR and RetinaNet, were trained on foosball data, once with a single figure class, and once with positional classes. The Detection Transformer (DETR) showed better performance on synthetic data for positionally labelled classes on synthetic data. For results, see the thesis PDF in this repo.

## Folders

**datasets:** the dataloader classes used for the training of both models  
**RetinaNet:** experiments done running RetinaNet  
**detr_experiments:** experiments done running DETR  
**Segmentsai:** named after the software I used, this contains the scripts to import the hand-labelled foosball data, and also the synthesiser for the synthetic data  
**models:** DETR model classes, I did not edit this  
**utils:** DETR utils, I did not edit this  
**test_images:** a few examples of outputs  

### Other important files

**engine.py:** contains the DETR evaluator class  

## Reproducibility

This section associates the experimental scripts with the Figures in my thesis PDF.    

Figure 2.2: detr_experiments/visualise_backbone.py  

Figure 4.1: Segmentsai/download_coco.py  
Figure 4.2: RetinaNet/test_retinanet.py  
Figure 4.3: Segmentsai/synthesiser/synthesiser.py  
Figure 4.4: Segmentsai/synthesiser/synthesiser.py  
Figure 4.5: detr_experiments/train_29.py and detr_experiments/read_logs.py  
Figure 4.6: detr_experiments/train_29.py, RetinaNet/main.py and detr_experiments/read_csvs.py  
Figure 4.7: detr_experiments/test_detr.py  
Figure 4.8: detr_experiments/visualise_queries.py  
Figure 4.9: detr_experiments/visualise_queries.py  
Figure 4.10: detr_experiments/visualise_encoder_attention.py  
Figure 4.11: detr_experiments/visualise_decoder_attention.py  
Figure 4.12: detr_experiments/visualise_decoder_attention.py  
Figure 4.13: RetinaNet/test_retinanet.py  
Figure 4.14: detr_experiments/train_29.py and detr_experiments/read_logs.py  
Figure 4.15: detr_experiments/train_29.py, RetinaNet/main.py and detr_experiments/read_csvs.py  
Figure 4.16: detr_experiments/visualise_encoder_attention.py  
Figure 4.17: detr_experiments/visualise_decoder_attention.py  
Figure 4.18: detr_experiments/visualise_decoder_attention.py  
Figure 4.19: detr_experiments/visualise_decoder_attention.py  
Figure 4.20: detr_experiments/visualise_queries.py  
Figure 5.1: plot_final_bar.py  

Table 4.1: detr_experiments/test_detr.py and RetinaNet/test_retinanet.py  
Table 4.2: detr_experiments/test_detr.py and RetinaNet/test_retinanet.py  
Table 4.3: detr_experiments/visualise_queries.py  
Table 4.5: detr_experiments/test_detr.py and RetinaNet/test_retinanet.py  
Table 4.6: detr_experiments/test_detr.py and RetinaNet/test_retinanet.py  

Videos in presentation: RetinaNet/retinanet_visual.py was also used  
